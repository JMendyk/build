\section{Build Systems \`a la Carte}\label{sec-build}

The focus of this paper is on a variety of implementations of
\hs{Build}~\hs{c}~\hs{i}~\hs{k}~\hs{v}, given
a \emph{client-supplied} implementation of \hs{Tasks}~\hs{c}~\hs{k}~\hs{v}. That
is, we are going to take \hs{Tasks} as given from now on, and explore variants of
\hs{Build}: first abstractly (in this section) and then concretely
in~\S\ref{sec-implementations}.

As per the definition of minimality~\ref{def-minimal}, a minimal build
system must \textbf{rebuild only out-of-date keys} and at most once. The only
way to achieve the ``at most once'' requirement while producing a correct build
result (\S\ref{sec-build-correctness}) is to \textbf{build all keys in an
order that respects their dependencies}.

\vspace{1mm}
We have bolded two different phrases above and, as we will see, the part of the
build system responsible for scheduling tasks in the dependency order
(a `scheduler') can be cleanly separated from the part responsible for deciding
whether a key needs to be rebuilt (a `rebuilder'). We therefore tackle each
aspect separately in subsections~\S\ref{sec-dependency-orderings}
and~\S\ref{sec-out-of-date}.

\subsection{Respecting the dependency order}
\label{sec-dependency-orderings}

Section \S\ref{sec-background} introduced three different \emph{task schedulers}
that decide which tasks to execute and in what order; see the ``Scheduler'' column
of Table~\ref{tab-summary} in \S\ref{sec-background-summary}.
This subsection explores the properties of the three schedulers, and
possible implementations.

\vspace{-2mm}
\subsubsection{Topological}\label{sec-topological}

The topological scheduler pre-computes a linear order of tasks, which when followed,
ensures the build result is correct regardless of the initial store. Given a
task description and the output \hs{key}, you can compute the linear order by
first finding the (acyclic) graph of the \hs{key}'s reachable dependencies, and
then computing a topological sort. However, as we have seen in~\S\ref{sec-deps},
we can only extract dependencies from an applicative task, which requires the
build system to choose \hs{c}~\hs{=}~\hs{Applicative}, ruling out dynamic
dependencies.

\vspace{-2mm}
\subsubsection{Restarting}\label{sec-restarting}

The topological scheduler has two downsides: it is limited to \hs{Applicative}
build systems and requires a fresh topological sort each time. \simon{If the tasks don't change,
  the dependencies are unchanged, so the topological sort from the last time
  will do fine, won't it?}  So, while the
actions themselves may be incremental (i.e. unnecessary tasks will not be
performed), the pre-processing is not. We can incrementalise the topological
sort by storing the topological order between build runs, using it as a starting
point in the next run, fixing it up if the build discovers any inconsistency, as
\Excel does.

This approach requires a way to abort tasks that have failed due to out-of-date
dependencies. It is also not minimal in the sense that a task may start, do some
meaningful work, and then abort. However, in the case of an \hs{Applicative}
system, that work is zero.

\Bazel's restarting scheduler does not store the topological order between build
runs; instead, it stores the most recent task dependency information. Since this
information may become outdated, \Bazel may also need to abort a task if a
newly discovered dependency is out-of-date.

\vspace{-2mm}
\subsubsection{Suspending}\label{sec-suspending}

An alternative approach, utilised by the \hs{busy} build system
(\S\ref{sec-general-build}) and \Shake, is to simply build dependencies when
they are requested, suspending the currently running task. By combining that
with tracking the keys that have already been built, one can obtain a minimal
build system with dynamic dependencies.

This approach requires that a task may be started and then suspended until
another task is complete. This can be done with cheap green threads and blocking
(the original approach of \Shake) or using continuation-passing style (what
\Shake does currently).

% An alternative approach to suspending a task is to abort
% it and restart it again later, at the cost of doing additional work.

\subsection{Determining out-of-date keys} \label{sec-out-of-date}

Suppose the scheduler decides that that a key \hs{k} should be
brought up to date.  The next question is: does any work need to be done,
or is it already up to date?   Or, in a cloud-build system, do we have
a cached copy of the value we need?
These questions can be addressed in one of four
fundamental ways, with a number of tweaks and variations within them.

\vspace{-2mm}
\subsubsection{A dirty bit}\label{sec-dirty-bit}

The idea of a dirty bit is to have one piece of persistent information per key,
saying whether the key is \emph{dirty} or \emph{clean}. After a build, all bits
are set to clean. When the next build starts, anything that changed between the
two states is marked dirty.
% ; and by marking additional things dirty/clean the build system can track
% what needs to rebuild.
If a key and all its transitive dependencies are clean, the key does not need
to be rebuild.

\Excel models the dirty bit approach most directly, having an actual dirty bit
associated with each cell, marking the cell dirty if the user modifies it, and
also making sure all cells that depend on it are recursively marked dirty too.
\simon{Not always (see make) and only possible if we have static dependencies
  or have recorded dynamic dependencies.}
When rebuilding, if a clean cell only depends on clean cells it is skipped,
otherwise it is rebuilt. \simon{But if all the dependencies of a dirty cell
  are marked dirty, we rebuild only dirty cells not clean ones, contradicting this statement.}

% AM: I didn't understand this bit, so commented it out.
% The only wrinkle in this scheme is that \Excel supports
% monadic tasks, and does not separately record the rebuilt, so it has
% to approximate in this case.

\Make uses file modification times, and compares files to their
dependencies, which can be thought of as a dirty bit which is set when
a file is newer than its dependencies. The interesting property of
this dirty bit is that it is not under the control of \Make; rather it is
existing file-system information that has been repurposed. In particular,
modifying a file automatically clears its dirty bit, and
automatically sets the dirty bit of the nodes depending on it. One
thing \Make does require is that file timestamps only go forward in
time -- something that can be violated by backup software. \simon{Also transitive dependencies
  of dirty files are not made dirty.}

When using a dirty bit, it is necessary to check all the dependencies of a key.
For applicative build systems that list is easy to obtain, but for monadic
build systems there is no general way to get all dependencies. Instead \Excel
computes a \emph{static approximation} of the dependencies. For applicative
tasks that approximation is correct. For functions such as \cmd{IF} it marks the
cell dirty if \emph{any} potential dependency has changed, even on the untaken
\cmd{IF} branch. For functions such as \cmd{INDIRECT} whose dependencies cannot
be guessed, it conservatively assumes the dependencies have always changed.

With a dirty bit it is simple to achieve minimality. However, to achieve early
cutoff (\S\ref{sec-background-shake}) it would be important to not set the dirty
bit after a computation that did not change the value. \simon{And if we'd recursively
made the transitive dependencies dirty, we could not do early cutoff.}
\Excel could use this
approach, but does not. \simon{It'd be tricky becase of setting dirtiness recursively.}
In contrast, \Make cannot implement early cutoff nicely
-- to do so it would have to mark the key clean (so it would not rebuild in the next
run) and at the same time not mark the keys that depend on it dirty -- an
impossible task with only the ability to update to the latest modification time.
\Make can approximate early cutoff by not modifying the result file, and not
marking it clean, but then it will rerun in every subsequent build.

\vspace{-2mm}
\subsubsection{Verifying traces}\label{sec-verifying-traces}

An alternative way to determine if a key is dirty is to record the
values/hashes of dependencies used last time, and if something has changed, the
key is dirty and must be rebuilt~--~in essence a \emph{trace} which we can use
to \emph{verify} existing values. For traces, there are two essential
operations~--~adding a new value to the trace store, and using the traces to
determine if a key needs rebuilding. Assuming a store of verifying traces
\hs{VT}~\hs{k}~\hs{v}, the operations are:

\begin{minted}[fontsize=\small,xleftmargin=10pt]{haskell}
recordVT@\,@::@\,@k -> Hash v -> [(k, Hash v)] -> VT k v -> VT k v
verifyVT@\,@::@\,@(Monad m,@\,@Eq k,@\,@Eq v) => k -> Hash v -> (k -> m (Hash v)) -> VT k v -> m Bool
\end{minted}

\noindent
Rather than storing (large) values \hs{v}, the verifying trace \hs{VT} stores
only hashes, of type \hs{Hash}~\hs{v}, of those values. Since the verifying
trace persists from one build to the next -- it constitutes the build system's
``memory'' -- it is helpful for it to be of modest size. After successfully
building a key, we call \hs{recordVT} to add a record to the current \hs{VT},
passing the key, the hash of its value, and the list of hashes and dependencies.

More interestingly, to \emph{verify} whether a key needs rebuilding we supply
the key, the hash of its current value, a function for obtaining the post-build
value of any key (using a scheduling strategy as per
\S\ref{sec-dependency-orderings}), and the existing \hs{VT} information. The
result will be a \hs{Bool} where \hs{True} indicates that the current value is
already up to date, and \hs{False} indicates that it should be rebuilt.

One potential implementation would be to record all arguments passed to
\hs{recordVT} in a list, and verify by simply checking if any list item matches
the information passed by \hs{verifyVT}.  We discuss smarter implementations
in~\S\ref{sec-smart-traces}.

A verifying trace, and other types of traces discussed in this section, support
dynamic dependencies and minimality; furthermore, all traces except for deep
traces~(\S\ref{sec-deep-constructive-traces}) support early cutoff.

\subsubsection{Constructive traces}\label{sec-constructive-traces}

A verifying trace deliberately records only small hashes, so that it can be small.
A \emph{constructive} trace additionally stores the resulting value.
Once we are storing the complete result it makes sense
to record many constructive traces per key, and to share them with other users,
providing cloud-build functionality. We can represent this additional
information by providing the operations:

\begin{minted}[fontsize=\small,xleftmargin=10pt]{haskell}
recordCT    :: k -> v -> [(k, Hash v)] -> CT k v -> CT k v
constructCT :: (Monad m, Eq k, Eq v) => k -> (k -> m (Hash v)) -> CT k v -> m [v]
\end{minted}

\noindent
The function \hs{recordCT} looks like \hs{recordVT}, but instead of just passing
the hash of the resulting value, we require the whole value. The \hs{verifyVT}
has been replaced with \hs{constructCT}, which instead of taking the hash of the
current value as \emph{input}, returns a list of suitable values as \emph{output}.
If the current value in the store
matches one of the possible values, the build can skip this rule. If the
resulting list is empty, the key must be rebuilt. However, if the current value
does not match the store, and there is a possible value, we can use any value
from the constructive list \emph{without} doing any work to build it, and copy
it into the store from the cloud.

\subsubsection{Deep constructive traces}\label{sec-deep-constructive-traces}

Constructive traces always verify keys by looking at their immediate
dependencies, which must have first been brought up to date, meaning that the
time to verify a key is based on the number of transitive dependencies. A
\emph{deep} constructive trace optimises this process by only looking at the
terminal \emph{input keys}, ignoring any intermediate dependencies. The operations
capturing this approach are the same as for constructive traces
in~\S\ref{sec-constructive-traces}, but we use the names \hs{recordDCT} and
\hs{constructDCT}, where the underlying \hs{DCT} representation need only record
information about hashes of inputs, not intermediate dependencies.

Current build systems using deep constructive traces always record hashes of
terminal \emph{input keys}, but the technique works equally well if we skip any
number of dependency levels (say $n$ levels). The input-only approach is the
special case of $n = \infty$, and constructive traces are the special case of
$n = 1$.

The deep constructive trace approach only works if the operations are
\emph{deterministic}, otherwise inconsistencies arise
(see~\S\ref{sec-non-determinism}). \simon{That section doesn't actually
  mention ``inconsistencies''.
  Also I think the inconsistencies are called Frankenbuilds, a term we might
  want to introduce.}
Concretely, if the result of building a key
given a set of immediate dependencies can vary, then it is possible that key
\hs{k} will have been computed locally, but something \emph{using} \hs{k} will
have been taken as a constructive input using a different value for \hs{k}. If
another rule combines those two values then two different values of \hs{k} will
have been used in one rule, leading to problems such as link-errors for typical
compilers.

A downside of deep constructive traces is that they cannot support cutoff
(\S\ref{sec-background-shake}), other than at the $n$ levels of dependencies. On
the other hand, these traces are particularly useful for ``shallow builds'', as
discussed in~\S\ref{sec-cloud-aspects}.

\subsection{Smarter \hs{[Trace]} data structures}\label{sec-smart-traces}

In the examples above, we have used abstract types for the traces. Concretely, in our example code, they are all recorded as lists of:

\begin{minted}[xleftmargin=10pt]{haskell}
data Trace k v r = Trace { key :: k, depends :: [(k, Hash v)], result :: r }
\end{minted}

\noindent
Here \hs{r} is either \hs{Hash}~\hs{v} (verifying traces) or
\hs{v} (constructive traces). A real system is highly likely to use a more
optimised implementation. Some of the most obvious optimisations are:

\begin{enumerate}
\item Any system using verifying traces, e.g. \Shake, is unlikely to see
significant benefit from storing more than one \hs{Trace} per key\footnote{There
is a small chance of a benefit if the dependencies change but the result does
not, and then the dependencies change back to what they were before.}.
Therefore, such systems can store \hs{Map}~\hs{k}~\hs{(Trace}~\hs{k}~\hs{v}~\hs{(Hash v))},
where the initial \hs{k} is the \hs{key} field of \hs{Trace}.

\item Any system using \hs{Applicative} dependencies can omit the dependency
keys from the \hs{Trace} since they can be recovered from the \hs{key} field.

\item Any \hs{Applicative} build system using constructive traces, e.g.
\Bazel, can index directly from the key and results to the output result~--~i.e.
\hs{Map}~\hs{(@@k,}~\hs{[Hash}~\hs{v])}~\hs{v}. Importantly, assuming the traces
are stored on a central server, the client can compute the key and the hashes of
its dependencies, then make a single call to the server to retrieve the result.

\item Many cloud build systems store hashes of values in the trace information,
then have a separate content-addressable cache which associates hashes with
their actual contents.
\end{enumerate}

\subsection{Build Systems \`a la Carte}\label{sec-design-space}

\begin{table}
\vspace{-1mm}
\smaller
\centering
\begin{tabular}{l||c|c|c}
\hline
 & \multicolumn{3}{c}{Scheduling strategy} \\
Out-of-date key strategy  & Topological\hspace{2mm}\S\ref{sec-topological} & Restarting\hspace{2mm}\S\ref{sec-restarting} & Suspending\hspace{2mm}\S\ref{sec-suspending}    \\\hline
\hline
Dirty bit\hfill\S\ref{sec-dirty-bit}                                                             & \Make       & \Excel & -              \\\hline
Verifying traces\hfill\S\ref{sec-verifying-traces}                                               & \Ninja      & -      & \Shake         \\\hline
Constructive traces\hspace{2mm}\hfill\S\ref{sec-constructive-traces}                             & \CloudBuild & \Bazel & -              \\\hline
Deep constructive traces\hspace{2mm}\hfill\S\ref{sec-deep-constructive-traces} & \Buck       & -      & \Nix           \\\hline
\end{tabular}
\vspace{1mm}
\caption{Build systems \`a la carte.\label{tab-build-systems}}
\vspace{-8mm}
\end{table}

With the information in this section we can build Table~\ref{tab-build-systems},
which tabulates combinations of the scheduling strategy and the out-of-date keys
strategy, providing 12~possible build systems, 8~of which are actually inhabited
by existing build systems (we discuss all these systems in
\S\ref{sec-related-build}). Of the remaining 4~spots, all result in workable
build systems. The most interesting unfilled spot in the table is suspending
constructive traces, which would provide many benefits, and which we title
\Cloud \Shake and further explore further in~\S\ref{sec-implementation-cloud}.
% (as we plan on extending \Shake to occupy that spot)
