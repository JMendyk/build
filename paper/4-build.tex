\section{Build Systems \`a la Carte}\label{sec-build}

The focus of this paper is on a variety of implementations of
\hs{Build}~\hs{c}~\hs{i}~\hs{k}~\hs{v}, given
a \emph{client-supplied} implementation of \hs{Task}~\hs{c}~\hs{k}~\hs{v}. That
is, we are going to take \hs{Task} as given from now on, and explore variants of
\hs{Build}: first abstractly (in this section) and then concretely
in~\S\ref{sec-implementations}.

As per the definition of minimality~\ref{def-minimal}, a minimal build
system must \textbf{rebuild only out-of-date keys} and at most once. The only
way to achieve the ``at most once'' requirement while producing a correct build
result (\S\ref{sec-build-correctness}) is to \textbf{build all keys in an
order that respects their dependencies}.

\vspace{1mm}
We have bolded two different phrases above, and tackle each aspect separately.

\subsection{Respecting the dependency order}
\label{sec-dependency-orderings}

The build systems overview (\S\ref{sec-background-summary}) highlighted three
distinct approaches to respecting the dependency order. This subsection explores
their properties and possible implementations.

\vspace{-2mm}
\subsubsection{Topological}\label{sec-topological}

The topological approach pre-computes a linear order, which when followed, ensures
the \hs{build} is correct regardless of the initial \hs{store}. Given a function
from a key to its dependencies, and the output \hs{key}, you can compute the
linear order by first finding the reachable dependencies of \hs{key},
and then computing a topological sort. However, as we have seen
in~\S\ref{sec-deps}, we can only extract dependencies from an applicative task,
which requires the build system to choose \hs{c}~\hs{=}~\hs{Applicative}, ruling
out dynamic dependencies.

\vspace{-2mm}
\subsubsection{Reordering}\label{sec-restarting}

The topological approach has two downsides: it is limited to \hs{Applicative}
build systems and requires a fresh topological sort each time.  So, while the
actions themselves may be incremental (i.e. unnecessary tasks will not be performed),
the pre-processing is not. We can try to incrementalise the topological sort by
storing the topological order between build runs and assume it to
be correct, but if the build discovers it is wrong, fix it up.

This approach requires a way to abort tasks that have failed due to out-of-date
dependencies. It is also not minimal in the sense that a task may start, do some
meaningful work, then abort. However, in the case of an \hs{Applicative} system,
that work is zero.

\vspace{-2mm}
\subsubsection{Recursive}\label{sec-suspending}

An alternative approach, utilised by the \hs{busy} build system
(\S\ref{sec-general-build}), is to simply build dependencies when they are
requested. By combining that with a transient set of which keys have already
been built, you can obtain a minimal build system.

This approach requires that a task may be started, then during that execution
another task will have to be run. Assuming an IO-driven task structure,
that requires suspending a running task, which can be done with cheap
green threads and blocking (the original approach of \Shake) or using
continuation-passing style (what \Shake does currently). An alternative approach to
suspending a task is to abort it and restart it again later, at the cost
of doing additional work.

\subsection{Determining out-of-date keys} \label{sec-out-of-date}

The second aspect, determining what to rebuild, can be addressed in one of three
fundamental ways, with a number of tweaks and variations within them.

\vspace{-2mm}
\subsubsection{A dirty bit}\label{sec-dirty-bit}

The idea of a dirty bit is to have one piece of persistent
information per key, saying whether the key is
\emph{dirty} or \emph{clean}. After a build, all bits are set to clean. When the
next build starts, anything that changed between the two states is marked
dirty.
% ; and by marking additional things dirty/clean the build system can track
% what needs to rebuild.
When reaching a key, if it and all its transitive dependencies are clean, the
key does not need recomputing.

\Excel models the dirty bit approach most directly, having an actual dirty bit
associated with each cell, marking the cell dirty if the user modifies it.
When rebuilding, if a cell only depends on clean cells it is skipped, otherwise
it is rebuilt and marked dirty so that the cells that depend on it are
subsequently rebuilt too.

% AM: I didn't understand this bit, so commented it out.
% The only wrinkle in this scheme is that \Excel supports
% monadic tasks, and does not separately record the rebuilt, so it has
% to approximate in this case.

\Make uses file modification times, and compares files to their
dependencies, which can be thought of as a dirty bit which is set when
a file is newer than its dependencies. The interesting property of
this dirty bit is that it is not under the control of \Make; rather it is
existing file-system information that has been repurposed. In particular,
modifying a file automatically clears its dirty bit, and
automatically sets the dirty bit of the nodes depending on it. One
thing \Make does require is that file timestamps only go forward in
time -- something that can be violated by backup software.

When using a dirty bit, it is necessary to check all the dependencies of a key.
For applicative build systems that list is easy to obtain, but for monadic
build systems there is no general way to get all dependencies. Instead \Excel
computes a \emph{static approximation} of the dependencies. For applicative
tasks that approximation is correct. For functions such as \cmd{IF} it marks the
cell dirty if \emph{any} potential dependency has changed, even on the untaken
\emph{if} branch. For functions such as \cmd{INDIRECT} whose dependencies cannot
be guessed, it conservatively assumes the dependencies have always changed.

With a dirty bit it is simple to achieve minimality. However, to achieve early cutoff
(\S\ref{sec-background-shake}) it would be important to not set the dirty bit
after a computation that did not change the value. \Excel could use this
approach, but does not. In contrast, \Make cannot implement early cutoff nicely -- to
do so it would have to mark the node clean (so it would not rebuild in the next
run) and at the same time not mark the things it depends on dirty -- an
impossible task with only the ability to update to the latest modification time.
\Make can approximate early cutoff by not modifying the result file, and not marking it clean,
but then it will rerun in every subsequent build.

\vspace{-2mm}
\subsubsection{Verifying traces}\label{sec-verifying-traces}

An alternative way to determine if a key is dirty is to record what state the
values/hashes of dependencies were used at last time, and if something has
changed, the key is dirty and must be recomputed -- in essence a \emph{trace}
which we can use to \emph{verify} existing values. We can describe a trace as:

\begin{minted}{haskell}
data Trace k v = Trace
    { key          :: k
    , dependencies :: [(k, Hash v)]
    , result       :: Hash v }
\end{minted}

We assume that \hs{Hash}~\hs{v} is a small constant size, constructed from hashing the
underlying \hs{v} rather than storing it directly. Checking a trace requires
ensuring all the dependencies are up to date (using whatever ordering strategy
as per \S\ref{sec-dependency-orderings}), then comparing if the dependencies are
same as the current value and that the result is the same.

A build system that uses verifying traces needs to persistently maintain a set
of traces. After computing a fresh value we add its \hs{Trace}~\hs{k}~\hs{v} to
the set. Therefore the information stored by a build system that verifies
traces can be modelled as a list or set~--~we chose \hs{[Trace}~\hs{k}~\hs{v]}
for simplicity. In practice, different build systems can optimise the data
structures used by traces for their specific use cases, which we discuss
in~\S\ref{sec-smart-traces}.

\subsubsection{Constructive traces}\label{sec-constructive-traces}

A verifying trace allows us to mark a key dirty and rebuild it. Extending that information we can store a \emph{constructive} trace which is the trace plus the actual result. Once we are storing the complete result it makes sense to record many constructive traces per key, and to share them with other users, providing cloud-build functionality. We can represent that as:

\begin{minted}{haskell}
data Traces k v = Traces
    { traces    :: [Trace k v]
    , contents  :: Map (Hash v) v }
\end{minted}

We have a list of traces, plus a \hs{Map} from the hash to the actual contents. Checking a trace is the same as before, but if the result is the only thing that is different we can simply retrieve a fresh result from \hs{contents} \emph{without} recomputing it. We split the traces and contents because in cloud interactions to a remote server the checking system may have to examine many traces/hashes, but only retrieve at most one complete file per key.

\subsection{Smarter \hs{[Trace]} data structures}\label{sec-smart-traces}

In the examples above, we have used \hs{[Trace}~\hs{k}~\hs{v]} to capture a list
of traces~--~however, using a list necessarily means that finding the right trace
takes $O(n)$. For each of the \hs{Trace} based systems it is possible to devise
a smarter representation, which we sketch below. Note that these implementations
do not avoid calls to \hs{compute}, merely overheads in the build system itself.

\begin{enumerate}
\item Any system using verifying traces, e.g. \Shake, is unlikely to see significant benefit from storing more than one \hs{Trace} per key\footnote{There is a small chance of a benefit if the dependencies change but the result does not, and then the dependencies change back to what they were before.}. Therefore, such systems can store \hs{Map}~\hs{k}~\hs{(Trace}~\hs{k}~\hs{v)}, where the initial \hs{k} is the \hs{key} field of \hs{Trace}.
\item Any system using \hs{Applicative} dependencies can omit the dependency keys from the \hs{Trace} as they can be recovered from the \hs{key} field.
\item Any \hs{Applicative} build system storing constructive traces, e.g. \Bazel, can index directly from the key and results to the output result~--~i.e. \hs{Map}~\hs{(@@k,}~\hs{[Hash}~\hs{v])}~\hs{(Hash}~\hs{v)}. Importantly, assuming the traces are stored on a central server, the client can compute the key and the hashes of its dependencies, then make a single call to the server to retrieve the result hash. In this formulation we have removed the possibility for a single key/dependency state to map to multiple different hashes, e.g. on a non-deterministic build~--~something \Bazel already prohibits which is discussed more in~\S\ref{sec-non-determinism}.
\item Finally, a \hs{Monad} build system with constructive traces can be stored as \hs{Map}~\hs{k}~\hs{(Choice}~\hs{k}~\hs{v)}, assuming a definition of \hs{Choice} as:
\begin{minted}[xleftmargin=10pt]{haskell}
data Choice k v = Choice k (Map (Hash v) (Choice k v))
                | Result (Hash v)
\end{minted}
Here the \hs{Choice} encodes a tree, asking successive questions about keys, and taking different branches based on the answers, until it reaches a final result. Implementing this structure over client-server communication requires either a chatty interface with lots of round-trips per \hs{Choice} step, or sending over a part of the tree that is not subsequently explored.
\end{enumerate}

\subsection{Build Systems \`a la Carte}\label{sec-design-space}

\begin{table}[h]
\smaller
\centering
\begin{tabular}{l||c|c|c}
\hline
Property           & Topological\hspace{2mm}\S\ref{sec-topological} & Restarting\hspace{2mm}\S\ref{sec-restarting} & Suspending\hspace{2mm}\S\ref{sec-suspending}    \\\hline
\hline
Dirty bit\hfill\S\ref{sec-dirty-bit}                    & \Make    & \Excel                   & Approximate \Shake*  \\\hline
Verifying trace\hfill\S\ref{sec-verifying-traces}       & \Ninja   & Traced \Excel*            & \Shake                      \\\hline
Constructive trace\hspace{2mm}\hfill\S\ref{sec-constructive-traces} & \Bazel   & Cloud \Excel*             & Cloud \Shake*                \\\hline
\end{tabular}
\vspace{2mm}
\caption{Build systems \`a la carte. Systems marked * are hypothetical systems that do not currently exist.\label{tab-build-systems}}
\vspace{-2mm}
\end{table}

With the information in this section we can build a table comparing the
dependency order strategy with the out-of-date keys strategy, providing 9~possible
build systems, 5~of which are actually inhabited by existing build systems
(we discuss \Ninja \cite{ninja} in \S\ref{sec-related-build}). Of the
remaining 4~spots, we believe neither Traced or Cloud \Excel make sense~--~the
\Excel approach of reordering combined with static approximations reduces
the memory usage significantly. However, as soon as you are paying the cost of
storing traces, that benefit is gone. The advantage of Approximate \Shake over
\Shake would be that it could avoid storing traces and having a separate
information database, but that advantage is minor compared to the technical
restrictions and approximations it would provide, so we consider it unlikely
to be built. The Cloud \Shake system is an interesting and important point in
the design space, which we explore further
in~\S\ref{sec-implementation-cloud}.
